{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPML7ly3H65xsNH91Mam3vP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethvedbitdesjan/SummerResearch/blob/main/ResNetSVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HAVq9V9ZPiP",
        "outputId": "fc09b156-251a-4c15-859b-941180cedf4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at content/; to attempt to forcibly remount, call drive.mount(\"content/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('content/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/content/MyDrive/SummerResearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY8p730FZUsH",
        "outputId": "1b3fdc1d-a41b-4751-abc6-ec89c8d554e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/content/MyDrive/SummerResearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cuml-cu11 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cupy-cuda11x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRiWtLHEswyh",
        "outputId": "b1e6d8af-8187-45e5-e7a0-1471f448cba5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: cuml-cu11 in /usr/local/lib/python3.10/dist-packages (23.6.0)\n",
            "Requirement already satisfied: cudf-cu11==23.6.* in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (23.6.0)\n",
            "Requirement already satisfied: cupy-cuda11x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (12.1.0)\n",
            "Requirement already satisfied: dask-cuda==23.6.* in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (23.6.0)\n",
            "Requirement already satisfied: dask-cudf-cu11==23.6.* in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (23.6.0)\n",
            "Requirement already satisfied: dask==2023.3.2 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (2023.3.2)\n",
            "Requirement already satisfied: distributed==2023.3.2.1 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (2023.3.2.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (1.2.0)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (0.57.1)\n",
            "Requirement already satisfied: raft-dask-cu11==23.6.* in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (23.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (1.10.1)\n",
            "Requirement already satisfied: treelite==3.2.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (3.2.0)\n",
            "Requirement already satisfied: treelite-runtime==3.2.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (3.2.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (5.3.1)\n",
            "Requirement already satisfied: cubinlinker-cu11 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (0.3.0.post1)\n",
            "Requirement already satisfied: cuda-python<12.0,>=11.7.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (11.8.2)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (2023.6.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (1.22.4)\n",
            "Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (0.2.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (23.1)\n",
            "Requirement already satisfied: pandas<1.6.0dev0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (1.5.3)\n",
            "Requirement already satisfied: protobuf<4.22,>=4.21.6 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (4.21.12)\n",
            "Requirement already satisfied: ptxcompiler-cu11 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (0.7.0.post1)\n",
            "Requirement already satisfied: pyarrow==11.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (11.0.0)\n",
            "Requirement already satisfied: rmm-cu11==23.6.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (23.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (4.6.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (8.1.3)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (1.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (6.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (6.7.0)\n",
            "Requirement already satisfied: pynvml<11.5,>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-cuda==23.6.*->cuml-cu11) (11.4.1)\n",
            "Requirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-cuda==23.6.*->cuml-cu11) (3.0.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (3.1.2)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.0.5)\n",
            "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (2.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (6.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.26.16)\n",
            "Requirement already satisfied: pylibraft-cu11==23.6.* in /usr/local/lib/python3.10/dist-packages (from raft-dask-cu11==23.6.*->cuml-cu11) (23.6.1)\n",
            "Requirement already satisfied: ucx-py-cu11==0.32.* in /usr/local/lib/python3.10/dist-packages (from raft-dask-cu11==23.6.*->cuml-cu11) (0.32.0)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x>=12.0.0->cuml-cu11) (0.8.1)\n",
            "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cuml-cu11) (0.40.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<12.0,>=11.7.1->cudf-cu11==23.6.*->cuml-cu11) (0.29.35)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2023.3.2->cuml-cu11) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2023.3.2.1->cuml-cu11) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6.0dev0,>=1.3->cudf-cu11==23.6.*->cuml-cu11) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6.0dev0,>=1.3->cudf-cu11==23.6.*->cuml-cu11) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0dev0,>=1.3->cudf-cu11==23.6.*->cuml-cu11) (1.16.0)\n",
            "Requirement already satisfied: cupy-cuda11x in /usr/local/lib/python3.10/dist-packages (12.1.0)\n",
            "Requirement already satisfied: numpy<1.27,>=1.20 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x) (1.22.4)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x) (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cuml\n",
        "import cupy as cp"
      ],
      "metadata": {
        "id": "Bp7vcWJLszjf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Critical imports\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "import cv2\n",
        "import copy"
      ],
      "metadata": {
        "id": "PEKNw6ZqZaiO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "_JTNfTErZcot"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "funny_set = set()\n",
        "not_funny_set = set()\n",
        "with open('labelled_data/funny_combined1.csv', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        funny_set.add(line.strip())\n",
        "with open('labelled_data/not_funny_combined1.csv', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        not_funny_set.add(line.strip())"
      ],
      "metadata": {
        "id": "q6-CcPA0ZeG9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "train_funny_data = []\n",
        "train_not_funny_data = []\n",
        "count = 0\n",
        "added = set()\n",
        "for file in os.listdir('Funny_Originals_Final'):\n",
        "  img_array = Image.open(os.path.join('Funny_Originals_Final', file))\n",
        "  if file in funny_set:\n",
        "    added.add(file)\n",
        "    train_funny_data.append((img_array, 1))\n",
        "  if file in not_funny_set:\n",
        "    added.add(file)\n",
        "    train_not_funny_data.append((img_array, 0))\n",
        "  count += 1\n",
        "for file in os.listdir('Non-Funny_Modified_Final'):\n",
        "  img_array = Image.open(os.path.join('Non-Funny_Modified_Final', file))\n",
        "  if file in funny_set:\n",
        "    added.add(file)\n",
        "    train_funny_data.append((img_array, 1))\n",
        "  if file in not_funny_set:\n",
        "    added.add(file)\n",
        "    train_not_funny_data.append((img_array, 0))\n",
        "random.seed(123456)"
      ],
      "metadata": {
        "id": "xVTCXSR9ZgOQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(train_funny_data), len(train_not_funny_data))\n",
        "# train_not_funny_data1 = random.sample(train_not_funny_data, k = len(train_funny_data)+10)\n",
        "# train_data = train_funny_data + train_not_funny_data1\n",
        "# len(train_data), len(train_funny_data), len(train_not_funny_data), len(train_not_funny_data1)\n",
        "train_data = train_funny_data + train_not_funny_data"
      ],
      "metadata": {
        "id": "itjvVJ6BZill"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(train_data)"
      ],
      "metadata": {
        "id": "Ccpw4-2SZkOt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FunnyNotFunnyDataset(Dataset):\n",
        "    def __init__(self, data, root_dir=None, transform=None):\n",
        "        self.data = data\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, index):\n",
        "        image = self.data[index][0]\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "        label = self.data[index][1]\n",
        "        label_tensor = torch.zeros(1)\n",
        "        if label == 1:\n",
        "          label_tensor[0] = 1\n",
        "        return {'image_data':image, 'label':label_tensor}"
      ],
      "metadata": {
        "id": "lgUgnygfZlt5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetAdded(torch.nn.Module):\n",
        "  def __init__(self, resnet50=None, train_full=True):\n",
        "    super(ResNetAdded, self).__init__()\n",
        "    if resnet50:\n",
        "      self.resnet50 = resnet50\n",
        "    else:\n",
        "      self.resnet50 = models.resnet50(pretrained=True)\n",
        "    self.resnet50.fc = torch.nn.Identity()\n",
        "    self.classifier = torch.nn.Linear(2048, 1)\n",
        "    if not train_full:\n",
        "      for param in self.resnet50.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    x: A batch of images.\n",
        "\n",
        "    Returns: A tensor of predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    x = self.resnet50(x)\n",
        "    preds = self.classifier(x)\n",
        "    return preds\n",
        "\n",
        "  def feature_extractor(self, x):\n",
        "    features = self.resnet50(x)\n",
        "    return features"
      ],
      "metadata": {
        "id": "27QrlvCbbKxc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_train_split = int(0.6 * len(train_data))\n",
        "idx_test_split = int(0.8*len(train_data))\n",
        "model = ResNetAdded()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfoRbfKxZnmt",
        "outputId": "bb063fa5-4684-4d13-c131-b8378d55106a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "NUM_CLASSES = 1103\n",
        "BATCH_SIZE = 32\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "IMG_MEAN = [0.485, 0.456, 0.406]\n",
        "IMG_STD = [0.229, 0.224, 0.225]\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMG_MEAN, IMG_STD)\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMG_MEAN, IMG_STD)\n",
        "])\n",
        "train_dataset = FunnyNotFunnyDataset(train_data[:idx_train_split], transform = train_transform)\n",
        "valid_dataset = FunnyNotFunnyDataset(train_data[idx_train_split:idx_test_split], transform = train_transform)\n",
        "test_dataset = FunnyNotFunnyDataset(train_data[idx_test_split:] ,transform = test_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRyTWZ4EZw0f",
        "outputId": "4fda9a8c-85ce-4781-e505-d23c05cacded"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetAdded(\n",
              "  (resnet50): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (classifier): Linear(in_features=2048, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmvxtSbvaAuE",
        "outputId": "95b66fd4-6cf8-46f7-ab71-03a9d5df65f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "lr_sch = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "FNwKPEgcdhlS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 12\n",
        "best_valid_loss = 10000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print('epoch:', epoch)\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  total_loss = []\n",
        "  lrs = []\n",
        "  total_size = 0\n",
        "  correct = 0\n",
        "  for i, data in enumerate(train_dataloader):\n",
        "    inputs = data['image_data'].to(device)\n",
        "    label = data['label'].to(device)\n",
        "    inputs = inputs.type(torch.cuda.FloatTensor)\n",
        "    label = label.type(torch.cuda.FloatTensor)\n",
        "    output = model.forward(inputs)\n",
        "    gc.collect()\n",
        "    del inputs\n",
        "    loss = criterion(output, label)\n",
        "    loss.mean().backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.append(torch.sum(loss))\n",
        "    gc.collect()\n",
        "    del loss\n",
        "    torch.cuda.empty_cache()\n",
        "    predictions = torch.as_tensor((output - 0.5) >= 0, dtype=torch.int32)\n",
        "    correct += (predictions == label).float().sum().item()\n",
        "    gc.collect()\n",
        "    #gpu_usage()\n",
        "    del predictions\n",
        "    del label\n",
        "    del output\n",
        "    #gpu_usage()\n",
        "    torch.cuda.empty_cache()\n",
        "    #print(predictions, \"\\n\", targets, \"\\n\", correct)\n",
        "    total_size += BATCH_SIZE\n",
        "    accuracy = correct/(total_size)\n",
        "    #print(correct, total_size)\n",
        "    lrs.append(optimizer.param_groups[0]['lr'])\n",
        "  lr_sch.step()\n",
        "  print('Mean Train loss:', torch.mean(torch.stack(total_loss)), 'Train Accuracy:', accuracy)\n",
        "  model.eval()\n",
        "  total_size = 0\n",
        "  total_loss = []\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      for data in valid_dataloader:\n",
        "          gc.collect()\n",
        "          torch.cuda.empty_cache()\n",
        "          inputs = data[\"image_data\"].to(device)\n",
        "          targets = data[\"label\"].to(device)\n",
        "\n",
        "          inputs = inputs.type(torch.cuda.FloatTensor)\n",
        "          targets = targets.type(torch.cuda.FloatTensor)\n",
        "          #print(ids.shape, \"ids\")\n",
        "          batch_size = inputs.size(0)\n",
        "\n",
        "          output = model.forward(inputs)\n",
        "          gc.collect()\n",
        "          del inputs\n",
        "          loss = criterion(output, targets)\n",
        "          total_loss.append(torch.sum(loss))\n",
        "          gc.collect()\n",
        "          del loss\n",
        "          torch.cuda.empty_cache()\n",
        "          output = torch.sigmoid(output)\n",
        "\n",
        "          predictions = torch.as_tensor((output - 0.5) > 0, dtype=torch.int32)\n",
        "          if (predictions == targets).float().sum().item() > batch_size:\n",
        "            print('error?')\n",
        "          correct += (predictions == targets).float().sum().item()\n",
        "          gc.collect()\n",
        "          del predictions\n",
        "          del targets\n",
        "          del output\n",
        "          torch.cuda.empty_cache()\n",
        "          total_size += batch_size\n",
        "          #gpu_usage()\n",
        "      accuracy = correct/(total_size)\n",
        "  if torch.sum(torch.stack(total_loss)) < best_valid_loss:\n",
        "    best_valid_loss = torch.sum(torch.stack(total_loss))\n",
        "    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "    path = f\"best_model_full.bin\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Model Saved\")\n",
        "  print(\"Validation Loss over a batch: {:.4f}; Validation Loss over a single value: {:.4f} Validation Accuracy: {:.2f}%\".format(torch.mean(torch.stack(total_loss)),(torch.mean(torch.stack(total_loss)))/(batch_size*8), accuracy*100))\n",
        "  accuracy, correct, total_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J38JW0-Adp-_",
        "outputId": "67fa65ce-8062-49fd-d103-ec6dd84d5e2c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "Mean Train loss: tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.5649509803921569\n",
            "Model Saved\n",
            "Validation Loss over a batch: 1.0631; Validation Loss over a single value: 0.0049 Validation Accuracy: 59.18%\n",
            "epoch: 1\n",
            "Mean Train loss: tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.571078431372549\n",
            "Model Saved\n",
            "Validation Loss over a batch: 0.6590; Validation Loss over a single value: 0.0031 Validation Accuracy: 59.18%\n",
            "epoch: 2\n",
            "Mean Train loss: tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.5716911764705882\n",
            "Validation Loss over a batch: 0.6963; Validation Loss over a single value: 0.0032 Validation Accuracy: 59.18%\n",
            "epoch: 3\n",
            "Mean Train loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.5692401960784313\n",
            "Validation Loss over a batch: 0.6896; Validation Loss over a single value: 0.0032 Validation Accuracy: 49.91%\n",
            "epoch: 4\n",
            "Mean Train loss: tensor(0.6949, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.5704656862745098\n",
            "Validation Loss over a batch: 0.7907; Validation Loss over a single value: 0.0037 Validation Accuracy: 59.18%\n",
            "epoch: 5\n",
            "Mean Train loss: tensor(0.6803, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.571078431372549\n",
            "Validation Loss over a batch: 0.8054; Validation Loss over a single value: 0.0037 Validation Accuracy: 60.11%\n",
            "epoch: 6\n",
            "Mean Train loss: tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.5704656862745098\n",
            "Validation Loss over a batch: 0.6682; Validation Loss over a single value: 0.0031 Validation Accuracy: 58.44%\n",
            "epoch: 7\n",
            "Mean Train loss: tensor(0.6780, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.5723039215686274\n",
            "Validation Loss over a batch: 0.6626; Validation Loss over a single value: 0.0031 Validation Accuracy: 61.41%\n",
            "epoch: 8\n",
            "Mean Train loss: tensor(0.6616, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.5765931372549019\n",
            "Validation Loss over a batch: 0.7313; Validation Loss over a single value: 0.0034 Validation Accuracy: 61.78%\n",
            "epoch: 9\n",
            "Mean Train loss: tensor(0.6625, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.5833333333333334\n",
            "Model Saved\n",
            "Validation Loss over a batch: 0.6391; Validation Loss over a single value: 0.0030 Validation Accuracy: 60.30%\n",
            "epoch: 10\n",
            "Mean Train loss: tensor(0.6464, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.5747549019607843\n",
            "Model Saved\n",
            "Validation Loss over a batch: 0.6390; Validation Loss over a single value: 0.0030 Validation Accuracy: 62.52%\n",
            "epoch: 11\n",
            "Mean Train loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) Train Accuracy: 0.5778186274509803\n",
            "Model Saved\n",
            "Validation Loss over a batch: 0.6385; Validation Loss over a single value: 0.0030 Validation Accuracy: 62.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_model_full.bin'))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaEbvrsF9nEY",
        "outputId": "3b541a0a-17d8-4a42-9550-a9e93ef8f03c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetAdded(\n",
              "  (resnet50): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (classifier): Linear(in_features=2048, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "total_size = 0\n",
        "total_loss = []\n",
        "correct = 0\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        inputs = data[\"image_data\"].to(device)\n",
        "        targets = data[\"label\"].to(device)\n",
        "\n",
        "        inputs = inputs.type(torch.cuda.FloatTensor)\n",
        "        targets = targets.type(torch.cuda.FloatTensor)\n",
        "        #print(ids.shape, \"ids\")\n",
        "        batch_size = inputs.size(0)\n",
        "\n",
        "        output = model.forward(inputs)\n",
        "        gc.collect()\n",
        "        del inputs\n",
        "        loss = criterion(output, targets)\n",
        "        total_loss.append(torch.sum(loss))\n",
        "        gc.collect()\n",
        "        del loss\n",
        "        torch.cuda.empty_cache()\n",
        "        output = torch.sigmoid(output)\n",
        "\n",
        "        predictions = torch.as_tensor((output - 0.5) > 0, dtype=torch.int32)\n",
        "        if (predictions == targets).float().sum().item() > batch_size:\n",
        "          print('error?')\n",
        "        all_preds += predictions.flatten().cpu().detach().tolist()\n",
        "        all_targets += targets.flatten().cpu().detach().tolist()\n",
        "        correct += (predictions == targets).float().sum().item()\n",
        "        gc.collect()\n",
        "        del predictions\n",
        "        del targets\n",
        "        del output\n",
        "        torch.cuda.empty_cache()\n",
        "        total_size += batch_size\n",
        "        #gpu_usage()\n",
        "    accuracy = correct/(total_size)\n",
        "print(\"Test Loss over a batch: {:.4f}; Test Loss over a single value: {:.4f} Test Accuracy: {:.2f}%\".format(torch.mean(torch.stack(total_loss)),(torch.mean(torch.stack(total_loss)))/(batch_size*8), accuracy*100))\n",
        "accuracy, correct, total_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUl9H2Hi9smy",
        "outputId": "3c18a599-6b79-4c89-cccb-325b5da3c053"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss over a batch: 0.6641; Test Loss over a single value: 0.0031 Test Accuracy: 56.96%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5695732838589982, 307.0, 539)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTnhPXbjSR6v",
        "outputId": "841d6d6b-722e-45aa-f02b-879bb722ca5e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "pd.DataFrame(confusion_matrix(all_preds, all_targets), columns=['Test Not Funny', 'Test Funny'], index=['Pred Not Funny', 'Pred Funny'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "308DrwkESCtR",
        "outputId": "5d9a74ac-9b0a-467a-846c-74b1168799f2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Test Not Funny  Test Funny\n",
              "Pred Not Funny             210         135\n",
              "Pred Funny                  97          97"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3a67459-6ba4-4bee-a865-22fd687b1b90\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Not Funny</th>\n",
              "      <th>Test Funny</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pred Not Funny</th>\n",
              "      <td>210</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pred Funny</th>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3a67459-6ba4-4bee-a865-22fd687b1b90')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3a67459-6ba4-4bee-a865-22fd687b1b90 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3a67459-6ba4-4bee-a865-22fd687b1b90');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azOWTlxVqX6s",
        "outputId": "0a94368a-7137-4665-8182-726b22ccd666"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetAdded(\n",
              "  (resnet50): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (classifier): Linear(in_features=2048, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size = 1, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle=True)"
      ],
      "metadata": {
        "id": "k01CSgkbXs7G"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "funny_num = 0\n",
        "for data in train_dataloader:\n",
        "  targets = data[\"label\"].to(device)\n",
        "  funny_num += int(torch.sum(targets.flatten()))\n",
        "funny_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t07b2He023f4",
        "outputId": "005662c2-baa4-402a-e561-1f0805607d5e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "681"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_svm_x = []\n",
        "train_svm_y = []\n",
        "test_svm_x = []\n",
        "test_svm_y = []\n",
        "not_funny_num = 0\n",
        "for data in train_dataloader:\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  inputs = data[\"image_data\"].to(device)\n",
        "  targets = data[\"label\"].to(device)\n",
        "\n",
        "  inputs = inputs.type(torch.cuda.FloatTensor)\n",
        "  targets = targets.type(torch.cuda.FloatTensor)\n",
        "  features = model.feature_extractor(inputs)\n",
        "  features = features.flatten()\n",
        "  targets = targets.flatten()\n",
        "  if int(torch.sum(targets.flatten())) == 0:\n",
        "    not_funny_num += 1\n",
        "    if not_funny_num > funny_num:\n",
        "      continue\n",
        "  #print(features.shape, targets.shape)\n",
        "  train_svm_x.append(cp.from_dlpack(features.detach()))\n",
        "  train_svm_y.append(cp.asarray(targets))"
      ],
      "metadata": {
        "id": "FjWAHMhKn0uy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp"
      ],
      "metadata": {
        "id": "PuSoOnf1yNaQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in test_dataloader:\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  inputs = data[\"image_data\"].to(device)\n",
        "  targets = data[\"label\"].to(device)\n",
        "\n",
        "  inputs = inputs.type(torch.cuda.FloatTensor)\n",
        "  targets = targets.type(torch.cuda.FloatTensor)\n",
        "  features = model.feature_extractor(inputs)\n",
        "  features = features.flatten()\n",
        "  targets = targets.flatten()\n",
        "  #print(features.shape, targets.shape)\n",
        "  test_svm_x.append(cp.from_dlpack(features.detach()))\n",
        "  test_svm_y.append(cp.asarray(targets))"
      ],
      "metadata": {
        "id": "4DqzFGc0ocyD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_svm_x)):\n",
        "  print(type(test_svm_x[i]), test_svm_x[i].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBjwb49iTTV8",
        "outputId": "a63e4044-0a96-4b4a-ecc9-08f0b80450b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n",
            "<class 'cupy.ndarray'> (2048,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_svm_x = cp.array(train_svm_x[:-1])\n",
        "train_svm_x.shape, train_svm_x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn-pExKuaE_Q",
        "outputId": "e8c06190-abcc-44a7-9fc0-e32c6d07227d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1361, 2048), <CUDA Device 0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_svm_y, test_svm_x, test_svm_y = cp.array(train_svm_y[:-1]), cp.array(test_svm_x[:-1]), cp.array(test_svm_y[:-1])\n",
        "train_svm_y.shape, test_svm_x.shape, test_svm_y.shape, train_svm_y.device, test_svm_x.device, test_svm_y.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt8E0xqZiHWk",
        "outputId": "ec91afb4-6482-431c-e5f1-09bb6e2e9553"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1361, 1),\n",
              " (538, 2048),\n",
              " (538, 1),\n",
              " <CUDA Device 0>,\n",
              " <CUDA Device 0>,\n",
              " <CUDA Device 0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp.save('train_svm_x.npy', train_svm_x)"
      ],
      "metadata": {
        "id": "d1GqC4OgmS3q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp.save('train_svm_y.npy', train_svm_y)\n",
        "cp.save('test_svm_x.npy', test_svm_x)\n",
        "cp.save('test_svm_y.npy', test_svm_y)"
      ],
      "metadata": {
        "id": "Ejl9ZQJHra5v"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "del train_dataloader\n",
        "del train_dataset\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2brwQgvr3bt",
        "outputId": "cfb4f57a-7506-4e06-c928-e00c3e6bc3f5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(train_svm_y), len(train_svm_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvpCePyi6MPy",
        "outputId": "843ed589-5615-41dd-b51e-da7251e79155"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(680., dtype=float32), 1361)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cuml.svm import SVC\n",
        "svm = SVC()"
      ],
      "metadata": {
        "id": "lnT23MaOsEN0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm.fit(train_svm_x, train_svm_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4jw8-1-sPHX",
        "outputId": "b309cd5e-76ba-4726-d53d-c7c0430d5500"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cuml.metrics import accuracy_score\n",
        "y_pred = svm.predict(test_svm_x)\n",
        "accuracy_score(y_pred, test_svm_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG4rGuFf0hQ2",
        "outputId": "3de2a631-22a6-414d-b474-e8b79661622e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.565055787563324"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_svm_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stsS1q8k1yXo",
        "outputId": "fb99b1c1-ed07-454f-c310-b736fbf0d9da"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(538, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cuml.metrics import confusion_matrix\n",
        "pd.DataFrame(confusion_matrix(y_pred.flatten().astype(int), test_svm_y.flatten().astype(int)).get(), columns=['Test Not Funny', 'Test Funny'], index=['Pred Not Funny', 'Pred Funny'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "lPBYdPiN0tj2",
        "outputId": "ae4681b8-5972-47d8-81f5-f08e69134327"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Test Not Funny  Test Funny\n",
              "Pred Not Funny             124          51\n",
              "Pred Funny                 183         180"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24bc82dc-f641-4c51-a6c2-0901bcc1f79c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Not Funny</th>\n",
              "      <th>Test Funny</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pred Not Funny</th>\n",
              "      <td>124</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pred Funny</th>\n",
              "      <td>183</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24bc82dc-f641-4c51-a6c2-0901bcc1f79c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24bc82dc-f641-4c51-a6c2-0901bcc1f79c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24bc82dc-f641-4c51-a6c2-0901bcc1f79c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jN_mJ_E3S44A"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}